{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling the Bank Marketing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/bank-full.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's build pipelines for numeric and categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feat = df.drop('y', axis=1).select_dtypes(include=np.number).columns\n",
    "cat_feat = df.drop('y', axis=1).select_dtypes(include=['object']).columns\n",
    "X = df.drop('y', axis=1)\n",
    "y = df['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()) #('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('one_hot', OneHotEncoder())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_feat),\n",
    "        ('cat', categorical_transformer, cat_feat)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use a simple model to check if the pipeline is working fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier',  LogisticRegression(class_weight='balanced', random_state=0))\n",
    "])\n",
    "\n",
    "model = pipe.fit(X_train, y_train)\n",
    "target_names = y_test.unique().astype(str)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.97      0.85      0.91      7984\n",
      "         yes       0.42      0.83      0.56      1059\n",
      "\n",
      "    accuracy                           0.85      9043\n",
      "   macro avg       0.70      0.84      0.74      9043\n",
      "weighted avg       0.91      0.85      0.87      9043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0     1\n",
      "0  75.0  13.0\n",
      "1   2.0  10.0\n"
     ]
    }
   ],
   "source": [
    "print(round(pd.DataFrame(confusion_matrix(y_test, y_pred)/len(y_test)*1e2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's analyze multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=['Name', 'AUC', 'Gini', 'StdDev(%)', 'Time(s)'])\n",
    "\n",
    "for model in [\n",
    "    DummyClassifier,\n",
    "    LinearDiscriminantAnalysis,\n",
    "    LogisticRegression, \n",
    "    RidgeClassifier,\n",
    "    DecisionTreeClassifier,\n",
    "    RandomForestClassifier, \n",
    "    GradientBoostingClassifier,\n",
    "    MLPClassifier,\n",
    "    XGBClassifier,\n",
    "    LGBMClassifier\n",
    "]:\n",
    "    pipe = make_pipeline(preprocessor, model())\n",
    "    start_time = time()\n",
    "    kfold = StratifiedKFold(n_splits=5, random_state=1)\n",
    "    scores = cross_val_score(pipe, X_train, \n",
    "                             y_train, scoring='roc_auc', cv=kfold)\n",
    "    time_mod = time() - start_time\n",
    "    results = results.append({\n",
    "        'Name' : model.__name__, \n",
    "        'AUC' : round(scores.mean(), 2), \n",
    "        'Gini' : round(2*scores.mean()-1, 2), \n",
    "        'StdDev(%)' : round(1e2*scores.std(), 2), \n",
    "        'Time(s)': round(time_mod, 2)\n",
    "    }, ignore_index=True)\n",
    "    del pipe\n",
    "print('Done!')\n",
    "\n",
    "results = results.sort_values('Gini', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Gini</th>\n",
       "      <th>StdDev(%)</th>\n",
       "      <th>Time(s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.11</td>\n",
       "      <td>33.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.14</td>\n",
       "      <td>24.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.19</td>\n",
       "      <td>51.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.35</td>\n",
       "      <td>244.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.16</td>\n",
       "      <td>2.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.19</td>\n",
       "      <td>4.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.16</td>\n",
       "      <td>2.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.59</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Name   AUC  Gini  StdDev(%)  Time(s)\n",
       "8               XGBClassifier  0.93  0.87       0.11    33.13\n",
       "9              LGBMClassifier  0.94  0.87       0.05     5.15\n",
       "5      RandomForestClassifier  0.93  0.86       0.14    24.22\n",
       "6  GradientBoostingClassifier  0.93  0.85       0.19    51.32\n",
       "7               MLPClassifier  0.92  0.83       0.35   244.41\n",
       "1  LinearDiscriminantAnalysis  0.91  0.81       0.16     2.83\n",
       "2          LogisticRegression  0.91  0.81       0.19     4.78\n",
       "3             RidgeClassifier  0.91  0.81       0.16     2.05\n",
       "4      DecisionTreeClassifier  0.71  0.41       0.59     3.62\n",
       "0             DummyClassifier  0.50  0.00       0.36     1.72"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use Lightgbm Model in a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('lgbm',  LGBMClassifier())\n",
    "])\n",
    "\n",
    "model = pipe.fit(X_train, y_train)\n",
    "target_names = y_test.unique().astype(str)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.94      0.96      0.95      7984\n",
      "         yes       0.65      0.52      0.58      1059\n",
      "\n",
      "    accuracy                           0.91      9043\n",
      "   macro avg       0.79      0.74      0.76      9043\n",
      "weighted avg       0.90      0.91      0.91      9043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0    1\n",
      "0  85.0  3.0\n",
      "1   6.0  6.0\n"
     ]
    }
   ],
   "source": [
    "print(round(pd.DataFrame(confusion_matrix(y_test, y_pred)/len(y_test)*1e2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default parameters of LGBMClassifier\n",
    "\n",
    "\n",
    "### Core parameters\n",
    "1. num_iterations (100) \n",
    "2. learning_rate (0.1) \n",
    "3. num_leaves (31)\n",
    "\n",
    "### Learning Control Parameters\n",
    "4. max_depth (-1)\n",
    "5. min_data_in_leaf (20)\n",
    "6. bagging_fraction (1.0)\n",
    "7. feature_fraction (1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'lgbm__num_iterations': [2, 100, 200],\n",
    "    'lgbm__learning_rate': [0.01, 0.1, 1],\n",
    "    'lgbm__num_leaves': [3, 31, 301],\n",
    "    'lgbm__max_depth': [-1, 10, 100],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation accuracy: 0.91\n",
      "Test set score: 0.91\n",
      "Best parameters: {'lgbm__learning_rate': 0.1, 'lgbm__max_depth': -1, 'lgbm__num_iterations': 100, 'lgbm__num_leaves': 31}\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Test set score: {:.2f}\".format(grid.score(X_test, y_test)))\n",
    "print(\"Best parameters: {}\".format(grid.best_params_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
